// @generated by protobuf-ts 2.8.1
// @generated from protobuf file "lightning.proto" (package "lnrpc", syntax proto3)
// tslint:disable
import type { RpcTransport } from "@protobuf-ts/runtime-rpc";
import type { ServiceInfo } from "@protobuf-ts/runtime-rpc";
import { Lightning } from "./lightning.js";
import type { LookupHtlcResponse } from "./lightning.js";
import type { LookupHtlcRequest } from "./lightning.js";
import type { ListAliasesResponse } from "./lightning.js";
import type { ListAliasesRequest } from "./lightning.js";
import type { CustomMessage } from "./lightning.js";
import type { SubscribeCustomMessagesRequest } from "./lightning.js";
import type { SendCustomMessageResponse } from "./lightning.js";
import type { SendCustomMessageRequest } from "./lightning.js";
import type { RPCMiddlewareRequest } from "./lightning.js";
import type { RPCMiddlewareResponse } from "./lightning.js";
import type { CheckMacPermResponse } from "./lightning.js";
import type { CheckMacPermRequest } from "./lightning.js";
import type { ListPermissionsResponse } from "./lightning.js";
import type { ListPermissionsRequest } from "./lightning.js";
import type { DeleteMacaroonIDResponse } from "./lightning.js";
import type { DeleteMacaroonIDRequest } from "./lightning.js";
import type { ListMacaroonIDsResponse } from "./lightning.js";
import type { ListMacaroonIDsRequest } from "./lightning.js";
import type { BakeMacaroonResponse } from "./lightning.js";
import type { BakeMacaroonRequest } from "./lightning.js";
import type { ChannelBackupSubscription } from "./lightning.js";
import type { RestoreBackupResponse } from "./lightning.js";
import type { RestoreChanBackupRequest } from "./lightning.js";
import type { VerifyChanBackupResponse } from "./lightning.js";
import type { ChanBackupSnapshot } from "./lightning.js";
import type { ChanBackupExportRequest } from "./lightning.js";
import type { ChannelBackup } from "./lightning.js";
import type { ExportChannelBackupRequest } from "./lightning.js";
import type { ForwardingHistoryResponse } from "./lightning.js";
import type { ForwardingHistoryRequest } from "./lightning.js";
import type { PolicyUpdateResponse } from "./lightning.js";
import type { PolicyUpdateRequest } from "./lightning.js";
import type { FeeReportResponse } from "./lightning.js";
import type { FeeReportRequest } from "./lightning.js";
import type { DebugLevelResponse } from "./lightning.js";
import type { DebugLevelRequest } from "./lightning.js";
import type { GraphTopologyUpdate } from "./lightning.js";
import type { GraphTopologySubscription } from "./lightning.js";
import type { StopResponse } from "./lightning.js";
import type { StopRequest } from "./lightning.js";
import type { NetworkInfo } from "./lightning.js";
import type { NetworkInfoRequest } from "./lightning.js";
import type { QueryRoutesResponse } from "./lightning.js";
import type { QueryRoutesRequest } from "./lightning.js";
import type { NodeInfo } from "./lightning.js";
import type { NodeInfoRequest } from "./lightning.js";
import type { ChannelEdge } from "./lightning.js";
import type { ChanInfoRequest } from "./lightning.js";
import type { NodeMetricsResponse } from "./lightning.js";
import type { NodeMetricsRequest } from "./lightning.js";
import type { ChannelGraph } from "./lightning.js";
import type { ChannelGraphRequest } from "./lightning.js";
import type { DeleteAllPaymentsResponse } from "./lightning.js";
import type { DeleteAllPaymentsRequest } from "./lightning.js";
import type { DeletePaymentResponse } from "./lightning.js";
import type { DeletePaymentRequest } from "./lightning.js";
import type { ListPaymentsResponse } from "./lightning.js";
import type { ListPaymentsRequest } from "./lightning.js";
import type { PayReq } from "./lightning.js";
import type { PayReqString } from "./lightning.js";
import type { InvoiceSubscription } from "./lightning.js";
import type { PaymentHash } from "./lightning.js";
import type { ListInvoiceResponse } from "./lightning.js";
import type { ListInvoiceRequest } from "./lightning.js";
import type { AddInvoiceResponse } from "./lightning.js";
import type { Invoice } from "./lightning.js";
import type { SendToRouteRequest } from "./lightning.js";
import type { SendResponse } from "./lightning.js";
import type { SendRequest } from "./lightning.js";
import type { AbandonChannelResponse } from "./lightning.js";
import type { AbandonChannelRequest } from "./lightning.js";
import type { CloseStatusUpdate } from "./lightning.js";
import type { CloseChannelRequest } from "./lightning.js";
import type { ChannelAcceptRequest } from "./lightning.js";
import type { ChannelAcceptResponse } from "./lightning.js";
import type { DuplexStreamingCall } from "@protobuf-ts/runtime-rpc";
import type { FundingStateStepResp } from "./lightning.js";
import type { FundingTransitionMsg } from "./lightning.js";
import type { BatchOpenChannelResponse } from "./lightning.js";
import type { BatchOpenChannelRequest } from "./lightning.js";
import type { OpenStatusUpdate } from "./lightning.js";
import type { ChannelPoint } from "./lightning.js";
import type { OpenChannelRequest } from "./lightning.js";
import type { ClosedChannelsResponse } from "./lightning.js";
import type { ClosedChannelsRequest } from "./lightning.js";
import type { ChannelEventUpdate } from "./lightning.js";
import type { ChannelEventSubscription } from "./lightning.js";
import type { ListChannelsResponse } from "./lightning.js";
import type { ListChannelsRequest } from "./lightning.js";
import type { PendingChannelsResponse } from "./lightning.js";
import type { PendingChannelsRequest } from "./lightning.js";
import type { GetRecoveryInfoResponse } from "./lightning.js";
import type { GetRecoveryInfoRequest } from "./lightning.js";
import type { GetInfoResponse } from "./lightning.js";
import type { GetInfoRequest } from "./lightning.js";
import type { PeerEvent } from "./lightning.js";
import type { PeerEventSubscription } from "./lightning.js";
import type { ListPeersResponse } from "./lightning.js";
import type { ListPeersRequest } from "./lightning.js";
import type { DisconnectPeerResponse } from "./lightning.js";
import type { DisconnectPeerRequest } from "./lightning.js";
import type { ConnectPeerResponse } from "./lightning.js";
import type { ConnectPeerRequest } from "./lightning.js";
import type { VerifyMessageResponse } from "./lightning.js";
import type { VerifyMessageRequest } from "./lightning.js";
import type { SignMessageResponse } from "./lightning.js";
import type { SignMessageRequest } from "./lightning.js";
import type { NewAddressResponse } from "./lightning.js";
import type { NewAddressRequest } from "./lightning.js";
import type { SendManyResponse } from "./lightning.js";
import type { SendManyRequest } from "./lightning.js";
import type { Transaction } from "./lightning.js";
import type { ServerStreamingCall } from "@protobuf-ts/runtime-rpc";
import type { ListUnspentResponse } from "./lightning.js";
import type { ListUnspentRequest } from "./lightning.js";
import type { SendCoinsResponse } from "./lightning.js";
import type { SendCoinsRequest } from "./lightning.js";
import type { EstimateFeeResponse } from "./lightning.js";
import type { EstimateFeeRequest } from "./lightning.js";
import type { TransactionDetails } from "./lightning.js";
import type { GetTransactionsRequest } from "./lightning.js";
import type { ChannelBalanceResponse } from "./lightning.js";
import type { ChannelBalanceRequest } from "./lightning.js";
import { stackIntercept } from "@protobuf-ts/runtime-rpc";
import type { WalletBalanceResponse } from "./lightning.js";
import type { WalletBalanceRequest } from "./lightning.js";
import type { UnaryCall } from "@protobuf-ts/runtime-rpc";
import type { RpcOptions } from "@protobuf-ts/runtime-rpc";
// 
// Comments in this file will be directly parsed into the API
// Documentation as descriptions of the associated method, message, or field.
// These descriptions should go right above the definition of the object, and
// can be in either block or // comment format.
// 
// An RPC method can be matched to an lncli command by placing a line in the
// beginning of the description in exactly the following format:
// lncli: `methodname`
// 
// Failure to specify the exact name of the command will cause documentation
// generation to fail.
// 
// More information on how exactly the gRPC documentation is generated from
// this proto file can be found here:
// https://github.com/lightninglabs/lightning-api

/**
 * Lightning is the main RPC server of the daemon.
 *
 * @generated from protobuf service lnrpc.Lightning
 */
export interface ILightningClient {
    /**
     * lncli: `walletbalance`
     * WalletBalance returns total unspent outputs(confirmed and unconfirmed), all
     * confirmed unspent outputs and all unconfirmed unspent outputs under control
     * of the wallet.
     *
     * @generated from protobuf rpc: WalletBalance(lnrpc.WalletBalanceRequest) returns (lnrpc.WalletBalanceResponse);
     */
    walletBalance(input: WalletBalanceRequest, options?: RpcOptions): UnaryCall<WalletBalanceRequest, WalletBalanceResponse>;
    /**
     * lncli: `channelbalance`
     * ChannelBalance returns a report on the total funds across all open channels,
     * categorized in local/remote, pending local/remote and unsettled local/remote
     * balances.
     *
     * @generated from protobuf rpc: ChannelBalance(lnrpc.ChannelBalanceRequest) returns (lnrpc.ChannelBalanceResponse);
     */
    channelBalance(input: ChannelBalanceRequest, options?: RpcOptions): UnaryCall<ChannelBalanceRequest, ChannelBalanceResponse>;
    /**
     * lncli: `listchaintxns`
     * GetTransactions returns a list describing all the known transactions
     * relevant to the wallet.
     *
     * @generated from protobuf rpc: GetTransactions(lnrpc.GetTransactionsRequest) returns (lnrpc.TransactionDetails);
     */
    getTransactions(input: GetTransactionsRequest, options?: RpcOptions): UnaryCall<GetTransactionsRequest, TransactionDetails>;
    /**
     * lncli: `estimatefee`
     * EstimateFee asks the chain backend to estimate the fee rate and total fees
     * for a transaction that pays to multiple specified outputs.
     *
     * When using REST, the `AddrToAmount` map type can be set by appending
     * `&AddrToAmount[<address>]=<amount_to_send>` to the URL. Unfortunately this
     * map type doesn't appear in the REST API documentation because of a bug in
     * the grpc-gateway library.
     *
     * @generated from protobuf rpc: EstimateFee(lnrpc.EstimateFeeRequest) returns (lnrpc.EstimateFeeResponse);
     */
    estimateFee(input: EstimateFeeRequest, options?: RpcOptions): UnaryCall<EstimateFeeRequest, EstimateFeeResponse>;
    /**
     * lncli: `sendcoins`
     * SendCoins executes a request to send coins to a particular address. Unlike
     * SendMany, this RPC call only allows creating a single output at a time. If
     * neither target_conf, or sat_per_vbyte are set, then the internal wallet will
     * consult its fee model to determine a fee for the default confirmation
     * target.
     *
     * @generated from protobuf rpc: SendCoins(lnrpc.SendCoinsRequest) returns (lnrpc.SendCoinsResponse);
     */
    sendCoins(input: SendCoinsRequest, options?: RpcOptions): UnaryCall<SendCoinsRequest, SendCoinsResponse>;
    /**
     * lncli: `listunspent`
     * Deprecated, use walletrpc.ListUnspent instead.
     *
     * ListUnspent returns a list of all utxos spendable by the wallet with a
     * number of confirmations between the specified minimum and maximum.
     *
     * @generated from protobuf rpc: ListUnspent(lnrpc.ListUnspentRequest) returns (lnrpc.ListUnspentResponse);
     */
    listUnspent(input: ListUnspentRequest, options?: RpcOptions): UnaryCall<ListUnspentRequest, ListUnspentResponse>;
    /**
     *
     * SubscribeTransactions creates a uni-directional stream from the server to
     * the client in which any newly discovered transactions relevant to the
     * wallet are sent over.
     *
     * @generated from protobuf rpc: SubscribeTransactions(lnrpc.GetTransactionsRequest) returns (stream lnrpc.Transaction);
     */
    subscribeTransactions(input: GetTransactionsRequest, options?: RpcOptions): ServerStreamingCall<GetTransactionsRequest, Transaction>;
    /**
     * lncli: `sendmany`
     * SendMany handles a request for a transaction that creates multiple specified
     * outputs in parallel. If neither target_conf, or sat_per_vbyte are set, then
     * the internal wallet will consult its fee model to determine a fee for the
     * default confirmation target.
     *
     * @generated from protobuf rpc: SendMany(lnrpc.SendManyRequest) returns (lnrpc.SendManyResponse);
     */
    sendMany(input: SendManyRequest, options?: RpcOptions): UnaryCall<SendManyRequest, SendManyResponse>;
    /**
     * lncli: `newaddress`
     * NewAddress creates a new address under control of the local wallet.
     *
     * @generated from protobuf rpc: NewAddress(lnrpc.NewAddressRequest) returns (lnrpc.NewAddressResponse);
     */
    newAddress(input: NewAddressRequest, options?: RpcOptions): UnaryCall<NewAddressRequest, NewAddressResponse>;
    /**
     * lncli: `signmessage`
     * SignMessage signs a message with this node's private key. The returned
     * signature string is `zbase32` encoded and pubkey recoverable, meaning that
     * only the message digest and signature are needed for verification.
     *
     * @generated from protobuf rpc: SignMessage(lnrpc.SignMessageRequest) returns (lnrpc.SignMessageResponse);
     */
    signMessage(input: SignMessageRequest, options?: RpcOptions): UnaryCall<SignMessageRequest, SignMessageResponse>;
    /**
     * lncli: `verifymessage`
     * VerifyMessage verifies a signature over a msg. The signature must be
     * zbase32 encoded and signed by an active node in the resident node's
     * channel database. In addition to returning the validity of the signature,
     * VerifyMessage also returns the recovered pubkey from the signature.
     *
     * @generated from protobuf rpc: VerifyMessage(lnrpc.VerifyMessageRequest) returns (lnrpc.VerifyMessageResponse);
     */
    verifyMessage(input: VerifyMessageRequest, options?: RpcOptions): UnaryCall<VerifyMessageRequest, VerifyMessageResponse>;
    /**
     * lncli: `connect`
     * ConnectPeer attempts to establish a connection to a remote peer. This is at
     * the networking level, and is used for communication between nodes. This is
     * distinct from establishing a channel with a peer.
     *
     * @generated from protobuf rpc: ConnectPeer(lnrpc.ConnectPeerRequest) returns (lnrpc.ConnectPeerResponse);
     */
    connectPeer(input: ConnectPeerRequest, options?: RpcOptions): UnaryCall<ConnectPeerRequest, ConnectPeerResponse>;
    /**
     * lncli: `disconnect`
     * DisconnectPeer attempts to disconnect one peer from another identified by a
     * given pubKey. In the case that we currently have a pending or active channel
     * with the target peer, then this action will be not be allowed.
     *
     * @generated from protobuf rpc: DisconnectPeer(lnrpc.DisconnectPeerRequest) returns (lnrpc.DisconnectPeerResponse);
     */
    disconnectPeer(input: DisconnectPeerRequest, options?: RpcOptions): UnaryCall<DisconnectPeerRequest, DisconnectPeerResponse>;
    /**
     * lncli: `listpeers`
     * ListPeers returns a verbose listing of all currently active peers.
     *
     * @generated from protobuf rpc: ListPeers(lnrpc.ListPeersRequest) returns (lnrpc.ListPeersResponse);
     */
    listPeers(input: ListPeersRequest, options?: RpcOptions): UnaryCall<ListPeersRequest, ListPeersResponse>;
    /**
     *
     * SubscribePeerEvents creates a uni-directional stream from the server to
     * the client in which any events relevant to the state of peers are sent
     * over. Events include peers going online and offline.
     *
     * @generated from protobuf rpc: SubscribePeerEvents(lnrpc.PeerEventSubscription) returns (stream lnrpc.PeerEvent);
     */
    subscribePeerEvents(input: PeerEventSubscription, options?: RpcOptions): ServerStreamingCall<PeerEventSubscription, PeerEvent>;
    /**
     * lncli: `getinfo`
     * GetInfo returns general information concerning the lightning node including
     * it's identity pubkey, alias, the chains it is connected to, and information
     * concerning the number of open+pending channels.
     *
     * @generated from protobuf rpc: GetInfo(lnrpc.GetInfoRequest) returns (lnrpc.GetInfoResponse);
     */
    getInfo(input: GetInfoRequest, options?: RpcOptions): UnaryCall<GetInfoRequest, GetInfoResponse>;
    /**
     * * lncli: `getrecoveryinfo`
     * GetRecoveryInfo returns information concerning the recovery mode including
     * whether it's in a recovery mode, whether the recovery is finished, and the
     * progress made so far.
     *
     * @generated from protobuf rpc: GetRecoveryInfo(lnrpc.GetRecoveryInfoRequest) returns (lnrpc.GetRecoveryInfoResponse);
     */
    getRecoveryInfo(input: GetRecoveryInfoRequest, options?: RpcOptions): UnaryCall<GetRecoveryInfoRequest, GetRecoveryInfoResponse>;
    // TODO(roasbeef): merge with below with bool?

    /**
     * lncli: `pendingchannels`
     * PendingChannels returns a list of all the channels that are currently
     * considered "pending". A channel is pending if it has finished the funding
     * workflow and is waiting for confirmations for the funding txn, or is in the
     * process of closure, either initiated cooperatively or non-cooperatively.
     *
     * @generated from protobuf rpc: PendingChannels(lnrpc.PendingChannelsRequest) returns (lnrpc.PendingChannelsResponse);
     */
    pendingChannels(input: PendingChannelsRequest, options?: RpcOptions): UnaryCall<PendingChannelsRequest, PendingChannelsResponse>;
    /**
     * lncli: `listchannels`
     * ListChannels returns a description of all the open channels that this node
     * is a participant in.
     *
     * @generated from protobuf rpc: ListChannels(lnrpc.ListChannelsRequest) returns (lnrpc.ListChannelsResponse);
     */
    listChannels(input: ListChannelsRequest, options?: RpcOptions): UnaryCall<ListChannelsRequest, ListChannelsResponse>;
    /**
     *
     * SubscribeChannelEvents creates a uni-directional stream from the server to
     * the client in which any updates relevant to the state of the channels are
     * sent over. Events include new active channels, inactive channels, and closed
     * channels.
     *
     * @generated from protobuf rpc: SubscribeChannelEvents(lnrpc.ChannelEventSubscription) returns (stream lnrpc.ChannelEventUpdate);
     */
    subscribeChannelEvents(input: ChannelEventSubscription, options?: RpcOptions): ServerStreamingCall<ChannelEventSubscription, ChannelEventUpdate>;
    /**
     * lncli: `closedchannels`
     * ClosedChannels returns a description of all the closed channels that
     * this node was a participant in.
     *
     * @generated from protobuf rpc: ClosedChannels(lnrpc.ClosedChannelsRequest) returns (lnrpc.ClosedChannelsResponse);
     */
    closedChannels(input: ClosedChannelsRequest, options?: RpcOptions): UnaryCall<ClosedChannelsRequest, ClosedChannelsResponse>;
    /**
     *
     * OpenChannelSync is a synchronous version of the OpenChannel RPC call. This
     * call is meant to be consumed by clients to the REST proxy. As with all
     * other sync calls, all byte slices are intended to be populated as hex
     * encoded strings.
     *
     * @generated from protobuf rpc: OpenChannelSync(lnrpc.OpenChannelRequest) returns (lnrpc.ChannelPoint);
     */
    openChannelSync(input: OpenChannelRequest, options?: RpcOptions): UnaryCall<OpenChannelRequest, ChannelPoint>;
    /**
     * lncli: `openchannel`
     * OpenChannel attempts to open a singly funded channel specified in the
     * request to a remote peer. Users are able to specify a target number of
     * blocks that the funding transaction should be confirmed in, or a manual fee
     * rate to us for the funding transaction. If neither are specified, then a
     * lax block confirmation target is used. Each OpenStatusUpdate will return
     * the pending channel ID of the in-progress channel. Depending on the
     * arguments specified in the OpenChannelRequest, this pending channel ID can
     * then be used to manually progress the channel funding flow.
     *
     * @generated from protobuf rpc: OpenChannel(lnrpc.OpenChannelRequest) returns (stream lnrpc.OpenStatusUpdate);
     */
    openChannel(input: OpenChannelRequest, options?: RpcOptions): ServerStreamingCall<OpenChannelRequest, OpenStatusUpdate>;
    /**
     * lncli: `batchopenchannel`
     * BatchOpenChannel attempts to open multiple single-funded channels in a
     * single transaction in an atomic way. This means either all channel open
     * requests succeed at once or all attempts are aborted if any of them fail.
     * This is the safer variant of using PSBTs to manually fund a batch of
     * channels through the OpenChannel RPC.
     *
     * @generated from protobuf rpc: BatchOpenChannel(lnrpc.BatchOpenChannelRequest) returns (lnrpc.BatchOpenChannelResponse);
     */
    batchOpenChannel(input: BatchOpenChannelRequest, options?: RpcOptions): UnaryCall<BatchOpenChannelRequest, BatchOpenChannelResponse>;
    /**
     *
     * FundingStateStep is an advanced funding related call that allows the caller
     * to either execute some preparatory steps for a funding workflow, or
     * manually progress a funding workflow. The primary way a funding flow is
     * identified is via its pending channel ID. As an example, this method can be
     * used to specify that we're expecting a funding flow for a particular
     * pending channel ID, for which we need to use specific parameters.
     * Alternatively, this can be used to interactively drive PSBT signing for
     * funding for partially complete funding transactions.
     *
     * @generated from protobuf rpc: FundingStateStep(lnrpc.FundingTransitionMsg) returns (lnrpc.FundingStateStepResp);
     */
    fundingStateStep(input: FundingTransitionMsg, options?: RpcOptions): UnaryCall<FundingTransitionMsg, FundingStateStepResp>;
    /**
     *
     * ChannelAcceptor dispatches a bi-directional streaming RPC in which
     * OpenChannel requests are sent to the client and the client responds with
     * a boolean that tells LND whether or not to accept the channel. This allows
     * node operators to specify their own criteria for accepting inbound channels
     * through a single persistent connection.
     *
     * @generated from protobuf rpc: ChannelAcceptor(stream lnrpc.ChannelAcceptResponse) returns (stream lnrpc.ChannelAcceptRequest);
     */
    channelAcceptor(options?: RpcOptions): DuplexStreamingCall<ChannelAcceptResponse, ChannelAcceptRequest>;
    /**
     * lncli: `closechannel`
     * CloseChannel attempts to close an active channel identified by its channel
     * outpoint (ChannelPoint). The actions of this method can additionally be
     * augmented to attempt a force close after a timeout period in the case of an
     * inactive peer. If a non-force close (cooperative closure) is requested,
     * then the user can specify either a target number of blocks until the
     * closure transaction is confirmed, or a manual fee rate. If neither are
     * specified, then a default lax, block confirmation target is used.
     *
     * @generated from protobuf rpc: CloseChannel(lnrpc.CloseChannelRequest) returns (stream lnrpc.CloseStatusUpdate);
     */
    closeChannel(input: CloseChannelRequest, options?: RpcOptions): ServerStreamingCall<CloseChannelRequest, CloseStatusUpdate>;
    /**
     * lncli: `abandonchannel`
     * AbandonChannel removes all channel state from the database except for a
     * close summary. This method can be used to get rid of permanently unusable
     * channels due to bugs fixed in newer versions of lnd. This method can also be
     * used to remove externally funded channels where the funding transaction was
     * never broadcast. Only available for non-externally funded channels in dev
     * build.
     *
     * @generated from protobuf rpc: AbandonChannel(lnrpc.AbandonChannelRequest) returns (lnrpc.AbandonChannelResponse);
     */
    abandonChannel(input: AbandonChannelRequest, options?: RpcOptions): UnaryCall<AbandonChannelRequest, AbandonChannelResponse>;
    /**
     * lncli: `sendpayment`
     * Deprecated, use routerrpc.SendPaymentV2. SendPayment dispatches a
     * bi-directional streaming RPC for sending payments through the Lightning
     * Network. A single RPC invocation creates a persistent bi-directional
     * stream allowing clients to rapidly send payments through the Lightning
     * Network with a single persistent connection.
     *
     * @deprecated
     * @generated from protobuf rpc: SendPayment(stream lnrpc.SendRequest) returns (stream lnrpc.SendResponse);
     */
    sendPayment(options?: RpcOptions): DuplexStreamingCall<SendRequest, SendResponse>;
    /**
     *
     * SendPaymentSync is the synchronous non-streaming version of SendPayment.
     * This RPC is intended to be consumed by clients of the REST proxy.
     * Additionally, this RPC expects the destination's public key and the payment
     * hash (if any) to be encoded as hex strings.
     *
     * @generated from protobuf rpc: SendPaymentSync(lnrpc.SendRequest) returns (lnrpc.SendResponse);
     */
    sendPaymentSync(input: SendRequest, options?: RpcOptions): UnaryCall<SendRequest, SendResponse>;
    /**
     * lncli: `sendtoroute`
     * Deprecated, use routerrpc.SendToRouteV2. SendToRoute is a bi-directional
     * streaming RPC for sending payment through the Lightning Network. This
     * method differs from SendPayment in that it allows users to specify a full
     * route manually. This can be used for things like rebalancing, and atomic
     * swaps.
     *
     * @deprecated
     * @generated from protobuf rpc: SendToRoute(stream lnrpc.SendToRouteRequest) returns (stream lnrpc.SendResponse);
     */
    sendToRoute(options?: RpcOptions): DuplexStreamingCall<SendToRouteRequest, SendResponse>;
    /**
     *
     * SendToRouteSync is a synchronous version of SendToRoute. It Will block
     * until the payment either fails or succeeds.
     *
     * @generated from protobuf rpc: SendToRouteSync(lnrpc.SendToRouteRequest) returns (lnrpc.SendResponse);
     */
    sendToRouteSync(input: SendToRouteRequest, options?: RpcOptions): UnaryCall<SendToRouteRequest, SendResponse>;
    /**
     * lncli: `addinvoice`
     * AddInvoice attempts to add a new invoice to the invoice database. Any
     * duplicated invoices are rejected, therefore all invoices *must* have a
     * unique payment preimage.
     *
     * @generated from protobuf rpc: AddInvoice(lnrpc.Invoice) returns (lnrpc.AddInvoiceResponse);
     */
    addInvoice(input: Invoice, options?: RpcOptions): UnaryCall<Invoice, AddInvoiceResponse>;
    /**
     * lncli: `listinvoices`
     * ListInvoices returns a list of all the invoices currently stored within the
     * database. Any active debug invoices are ignored. It has full support for
     * paginated responses, allowing users to query for specific invoices through
     * their add_index. This can be done by using either the first_index_offset or
     * last_index_offset fields included in the response as the index_offset of the
     * next request. By default, the first 100 invoices created will be returned.
     * Backwards pagination is also supported through the Reversed flag.
     *
     * @generated from protobuf rpc: ListInvoices(lnrpc.ListInvoiceRequest) returns (lnrpc.ListInvoiceResponse);
     */
    listInvoices(input: ListInvoiceRequest, options?: RpcOptions): UnaryCall<ListInvoiceRequest, ListInvoiceResponse>;
    /**
     * lncli: `lookupinvoice`
     * LookupInvoice attempts to look up an invoice according to its payment hash.
     * The passed payment hash *must* be exactly 32 bytes, if not, an error is
     * returned.
     *
     * @generated from protobuf rpc: LookupInvoice(lnrpc.PaymentHash) returns (lnrpc.Invoice);
     */
    lookupInvoice(input: PaymentHash, options?: RpcOptions): UnaryCall<PaymentHash, Invoice>;
    /**
     *
     * SubscribeInvoices returns a uni-directional stream (server -> client) for
     * notifying the client of newly added/settled invoices. The caller can
     * optionally specify the add_index and/or the settle_index. If the add_index
     * is specified, then we'll first start by sending add invoice events for all
     * invoices with an add_index greater than the specified value. If the
     * settle_index is specified, the next, we'll send out all settle events for
     * invoices with a settle_index greater than the specified value. One or both
     * of these fields can be set. If no fields are set, then we'll only send out
     * the latest add/settle events.
     *
     * @generated from protobuf rpc: SubscribeInvoices(lnrpc.InvoiceSubscription) returns (stream lnrpc.Invoice);
     */
    subscribeInvoices(input: InvoiceSubscription, options?: RpcOptions): ServerStreamingCall<InvoiceSubscription, Invoice>;
    /**
     * lncli: `decodepayreq`
     * DecodePayReq takes an encoded payment request string and attempts to decode
     * it, returning a full description of the conditions encoded within the
     * payment request.
     *
     * @generated from protobuf rpc: DecodePayReq(lnrpc.PayReqString) returns (lnrpc.PayReq);
     */
    decodePayReq(input: PayReqString, options?: RpcOptions): UnaryCall<PayReqString, PayReq>;
    /**
     * lncli: `listpayments`
     * ListPayments returns a list of all outgoing payments.
     *
     * @generated from protobuf rpc: ListPayments(lnrpc.ListPaymentsRequest) returns (lnrpc.ListPaymentsResponse);
     */
    listPayments(input: ListPaymentsRequest, options?: RpcOptions): UnaryCall<ListPaymentsRequest, ListPaymentsResponse>;
    /**
     *
     * DeletePayment deletes an outgoing payment from DB. Note that it will not
     * attempt to delete an In-Flight payment, since that would be unsafe.
     *
     * @generated from protobuf rpc: DeletePayment(lnrpc.DeletePaymentRequest) returns (lnrpc.DeletePaymentResponse);
     */
    deletePayment(input: DeletePaymentRequest, options?: RpcOptions): UnaryCall<DeletePaymentRequest, DeletePaymentResponse>;
    /**
     *
     * DeleteAllPayments deletes all outgoing payments from DB. Note that it will
     * not attempt to delete In-Flight payments, since that would be unsafe.
     *
     * @generated from protobuf rpc: DeleteAllPayments(lnrpc.DeleteAllPaymentsRequest) returns (lnrpc.DeleteAllPaymentsResponse);
     */
    deleteAllPayments(input: DeleteAllPaymentsRequest, options?: RpcOptions): UnaryCall<DeleteAllPaymentsRequest, DeleteAllPaymentsResponse>;
    /**
     * lncli: `describegraph`
     * DescribeGraph returns a description of the latest graph state from the
     * point of view of the node. The graph information is partitioned into two
     * components: all the nodes/vertexes, and all the edges that connect the
     * vertexes themselves. As this is a directed graph, the edges also contain
     * the node directional specific routing policy which includes: the time lock
     * delta, fee information, etc.
     *
     * @generated from protobuf rpc: DescribeGraph(lnrpc.ChannelGraphRequest) returns (lnrpc.ChannelGraph);
     */
    describeGraph(input: ChannelGraphRequest, options?: RpcOptions): UnaryCall<ChannelGraphRequest, ChannelGraph>;
    /**
     * lncli: `getnodemetrics`
     * GetNodeMetrics returns node metrics calculated from the graph. Currently
     * the only supported metric is betweenness centrality of individual nodes.
     *
     * @generated from protobuf rpc: GetNodeMetrics(lnrpc.NodeMetricsRequest) returns (lnrpc.NodeMetricsResponse);
     */
    getNodeMetrics(input: NodeMetricsRequest, options?: RpcOptions): UnaryCall<NodeMetricsRequest, NodeMetricsResponse>;
    /**
     * lncli: `getchaninfo`
     * GetChanInfo returns the latest authenticated network announcement for the
     * given channel identified by its channel ID: an 8-byte integer which
     * uniquely identifies the location of transaction's funding output within the
     * blockchain.
     *
     * @generated from protobuf rpc: GetChanInfo(lnrpc.ChanInfoRequest) returns (lnrpc.ChannelEdge);
     */
    getChanInfo(input: ChanInfoRequest, options?: RpcOptions): UnaryCall<ChanInfoRequest, ChannelEdge>;
    /**
     * lncli: `getnodeinfo`
     * GetNodeInfo returns the latest advertised, aggregated, and authenticated
     * channel information for the specified node identified by its public key.
     *
     * @generated from protobuf rpc: GetNodeInfo(lnrpc.NodeInfoRequest) returns (lnrpc.NodeInfo);
     */
    getNodeInfo(input: NodeInfoRequest, options?: RpcOptions): UnaryCall<NodeInfoRequest, NodeInfo>;
    /**
     * lncli: `queryroutes`
     * QueryRoutes attempts to query the daemon's Channel Router for a possible
     * route to a target destination capable of carrying a specific amount of
     * satoshis. The returned route contains the full details required to craft and
     * send an HTLC, also including the necessary information that should be
     * present within the Sphinx packet encapsulated within the HTLC.
     *
     * When using REST, the `dest_custom_records` map type can be set by appending
     * `&dest_custom_records[<record_number>]=<record_data_base64_url_encoded>`
     * to the URL. Unfortunately this map type doesn't appear in the REST API
     * documentation because of a bug in the grpc-gateway library.
     *
     * @generated from protobuf rpc: QueryRoutes(lnrpc.QueryRoutesRequest) returns (lnrpc.QueryRoutesResponse);
     */
    queryRoutes(input: QueryRoutesRequest, options?: RpcOptions): UnaryCall<QueryRoutesRequest, QueryRoutesResponse>;
    /**
     * lncli: `getnetworkinfo`
     * GetNetworkInfo returns some basic stats about the known channel graph from
     * the point of view of the node.
     *
     * @generated from protobuf rpc: GetNetworkInfo(lnrpc.NetworkInfoRequest) returns (lnrpc.NetworkInfo);
     */
    getNetworkInfo(input: NetworkInfoRequest, options?: RpcOptions): UnaryCall<NetworkInfoRequest, NetworkInfo>;
    /**
     * lncli: `stop`
     * StopDaemon will send a shutdown request to the interrupt handler, triggering
     * a graceful shutdown of the daemon.
     *
     * @generated from protobuf rpc: StopDaemon(lnrpc.StopRequest) returns (lnrpc.StopResponse);
     */
    stopDaemon(input: StopRequest, options?: RpcOptions): UnaryCall<StopRequest, StopResponse>;
    /**
     *
     * SubscribeChannelGraph launches a streaming RPC that allows the caller to
     * receive notifications upon any changes to the channel graph topology from
     * the point of view of the responding node. Events notified include: new
     * nodes coming online, nodes updating their authenticated attributes, new
     * channels being advertised, updates in the routing policy for a directional
     * channel edge, and when channels are closed on-chain.
     *
     * @generated from protobuf rpc: SubscribeChannelGraph(lnrpc.GraphTopologySubscription) returns (stream lnrpc.GraphTopologyUpdate);
     */
    subscribeChannelGraph(input: GraphTopologySubscription, options?: RpcOptions): ServerStreamingCall<GraphTopologySubscription, GraphTopologyUpdate>;
    /**
     * lncli: `debuglevel`
     * DebugLevel allows a caller to programmatically set the logging verbosity of
     * lnd. The logging can be targeted according to a coarse daemon-wide logging
     * level, or in a granular fashion to specify the logging for a target
     * sub-system.
     *
     * @generated from protobuf rpc: DebugLevel(lnrpc.DebugLevelRequest) returns (lnrpc.DebugLevelResponse);
     */
    debugLevel(input: DebugLevelRequest, options?: RpcOptions): UnaryCall<DebugLevelRequest, DebugLevelResponse>;
    /**
     * lncli: `feereport`
     * FeeReport allows the caller to obtain a report detailing the current fee
     * schedule enforced by the node globally for each channel.
     *
     * @generated from protobuf rpc: FeeReport(lnrpc.FeeReportRequest) returns (lnrpc.FeeReportResponse);
     */
    feeReport(input: FeeReportRequest, options?: RpcOptions): UnaryCall<FeeReportRequest, FeeReportResponse>;
    /**
     * lncli: `updatechanpolicy`
     * UpdateChannelPolicy allows the caller to update the fee schedule and
     * channel policies for all channels globally, or a particular channel.
     *
     * @generated from protobuf rpc: UpdateChannelPolicy(lnrpc.PolicyUpdateRequest) returns (lnrpc.PolicyUpdateResponse);
     */
    updateChannelPolicy(input: PolicyUpdateRequest, options?: RpcOptions): UnaryCall<PolicyUpdateRequest, PolicyUpdateResponse>;
    /**
     * lncli: `fwdinghistory`
     * ForwardingHistory allows the caller to query the htlcswitch for a record of
     * all HTLCs forwarded within the target time range, and integer offset
     * within that time range, for a maximum number of events. If no maximum number
     * of events is specified, up to 100 events will be returned. If no time-range
     * is specified, then events will be returned in the order that they occured.
     *
     * A list of forwarding events are returned. The size of each forwarding event
     * is 40 bytes, and the max message size able to be returned in gRPC is 4 MiB.
     * As a result each message can only contain 50k entries. Each response has
     * the index offset of the last entry. The index offset can be provided to the
     * request to allow the caller to skip a series of records.
     *
     * @generated from protobuf rpc: ForwardingHistory(lnrpc.ForwardingHistoryRequest) returns (lnrpc.ForwardingHistoryResponse);
     */
    forwardingHistory(input: ForwardingHistoryRequest, options?: RpcOptions): UnaryCall<ForwardingHistoryRequest, ForwardingHistoryResponse>;
    /**
     * lncli: `exportchanbackup`
     * ExportChannelBackup attempts to return an encrypted static channel backup
     * for the target channel identified by it channel point. The backup is
     * encrypted with a key generated from the aezeed seed of the user. The
     * returned backup can either be restored using the RestoreChannelBackup
     * method once lnd is running, or via the InitWallet and UnlockWallet methods
     * from the WalletUnlocker service.
     *
     * @generated from protobuf rpc: ExportChannelBackup(lnrpc.ExportChannelBackupRequest) returns (lnrpc.ChannelBackup);
     */
    exportChannelBackup(input: ExportChannelBackupRequest, options?: RpcOptions): UnaryCall<ExportChannelBackupRequest, ChannelBackup>;
    /**
     *
     * ExportAllChannelBackups returns static channel backups for all existing
     * channels known to lnd. A set of regular singular static channel backups for
     * each channel are returned. Additionally, a multi-channel backup is returned
     * as well, which contains a single encrypted blob containing the backups of
     * each channel.
     *
     * @generated from protobuf rpc: ExportAllChannelBackups(lnrpc.ChanBackupExportRequest) returns (lnrpc.ChanBackupSnapshot);
     */
    exportAllChannelBackups(input: ChanBackupExportRequest, options?: RpcOptions): UnaryCall<ChanBackupExportRequest, ChanBackupSnapshot>;
    /**
     *
     * VerifyChanBackup allows a caller to verify the integrity of a channel backup
     * snapshot. This method will accept either a packed Single or a packed Multi.
     * Specifying both will result in an error.
     *
     * @generated from protobuf rpc: VerifyChanBackup(lnrpc.ChanBackupSnapshot) returns (lnrpc.VerifyChanBackupResponse);
     */
    verifyChanBackup(input: ChanBackupSnapshot, options?: RpcOptions): UnaryCall<ChanBackupSnapshot, VerifyChanBackupResponse>;
    /**
     * lncli: `restorechanbackup`
     * RestoreChannelBackups accepts a set of singular channel backups, or a
     * single encrypted multi-chan backup and attempts to recover any funds
     * remaining within the channel. If we are able to unpack the backup, then the
     * new channel will be shown under listchannels, as well as pending channels.
     *
     * @generated from protobuf rpc: RestoreChannelBackups(lnrpc.RestoreChanBackupRequest) returns (lnrpc.RestoreBackupResponse);
     */
    restoreChannelBackups(input: RestoreChanBackupRequest, options?: RpcOptions): UnaryCall<RestoreChanBackupRequest, RestoreBackupResponse>;
    /**
     *
     * SubscribeChannelBackups allows a client to sub-subscribe to the most up to
     * date information concerning the state of all channel backups. Each time a
     * new channel is added, we return the new set of channels, along with a
     * multi-chan backup containing the backup info for all channels. Each time a
     * channel is closed, we send a new update, which contains new new chan back
     * ups, but the updated set of encrypted multi-chan backups with the closed
     * channel(s) removed.
     *
     * @generated from protobuf rpc: SubscribeChannelBackups(lnrpc.ChannelBackupSubscription) returns (stream lnrpc.ChanBackupSnapshot);
     */
    subscribeChannelBackups(input: ChannelBackupSubscription, options?: RpcOptions): ServerStreamingCall<ChannelBackupSubscription, ChanBackupSnapshot>;
    /**
     * lncli: `bakemacaroon`
     * BakeMacaroon allows the creation of a new macaroon with custom read and
     * write permissions. No first-party caveats are added since this can be done
     * offline.
     *
     * @generated from protobuf rpc: BakeMacaroon(lnrpc.BakeMacaroonRequest) returns (lnrpc.BakeMacaroonResponse);
     */
    bakeMacaroon(input: BakeMacaroonRequest, options?: RpcOptions): UnaryCall<BakeMacaroonRequest, BakeMacaroonResponse>;
    /**
     * lncli: `listmacaroonids`
     * ListMacaroonIDs returns all root key IDs that are in use.
     *
     * @generated from protobuf rpc: ListMacaroonIDs(lnrpc.ListMacaroonIDsRequest) returns (lnrpc.ListMacaroonIDsResponse);
     */
    listMacaroonIDs(input: ListMacaroonIDsRequest, options?: RpcOptions): UnaryCall<ListMacaroonIDsRequest, ListMacaroonIDsResponse>;
    /**
     * lncli: `deletemacaroonid`
     * DeleteMacaroonID deletes the specified macaroon ID and invalidates all
     * macaroons derived from that ID.
     *
     * @generated from protobuf rpc: DeleteMacaroonID(lnrpc.DeleteMacaroonIDRequest) returns (lnrpc.DeleteMacaroonIDResponse);
     */
    deleteMacaroonID(input: DeleteMacaroonIDRequest, options?: RpcOptions): UnaryCall<DeleteMacaroonIDRequest, DeleteMacaroonIDResponse>;
    /**
     * lncli: `listpermissions`
     * ListPermissions lists all RPC method URIs and their required macaroon
     * permissions to access them.
     *
     * @generated from protobuf rpc: ListPermissions(lnrpc.ListPermissionsRequest) returns (lnrpc.ListPermissionsResponse);
     */
    listPermissions(input: ListPermissionsRequest, options?: RpcOptions): UnaryCall<ListPermissionsRequest, ListPermissionsResponse>;
    /**
     *
     * CheckMacaroonPermissions checks whether a request follows the constraints
     * imposed on the macaroon and that the macaroon is authorized to follow the
     * provided permissions.
     *
     * @generated from protobuf rpc: CheckMacaroonPermissions(lnrpc.CheckMacPermRequest) returns (lnrpc.CheckMacPermResponse);
     */
    checkMacaroonPermissions(input: CheckMacPermRequest, options?: RpcOptions): UnaryCall<CheckMacPermRequest, CheckMacPermResponse>;
    /**
     *
     * RegisterRPCMiddleware adds a new gRPC middleware to the interceptor chain. A
     * gRPC middleware is software component external to lnd that aims to add
     * additional business logic to lnd by observing/intercepting/validating
     * incoming gRPC client requests and (if needed) replacing/overwriting outgoing
     * messages before they're sent to the client. When registering the middleware
     * must identify itself and indicate what custom macaroon caveats it wants to
     * be responsible for. Only requests that contain a macaroon with that specific
     * custom caveat are then sent to the middleware for inspection. The other
     * option is to register for the read-only mode in which all requests/responses
     * are forwarded for interception to the middleware but the middleware is not
     * allowed to modify any responses. As a security measure, _no_ middleware can
     * modify responses for requests made with _unencumbered_ macaroons!
     *
     * @generated from protobuf rpc: RegisterRPCMiddleware(stream lnrpc.RPCMiddlewareResponse) returns (stream lnrpc.RPCMiddlewareRequest);
     */
    registerRPCMiddleware(options?: RpcOptions): DuplexStreamingCall<RPCMiddlewareResponse, RPCMiddlewareRequest>;
    /**
     * lncli: `sendcustom`
     * SendCustomMessage sends a custom peer message.
     *
     * @generated from protobuf rpc: SendCustomMessage(lnrpc.SendCustomMessageRequest) returns (lnrpc.SendCustomMessageResponse);
     */
    sendCustomMessage(input: SendCustomMessageRequest, options?: RpcOptions): UnaryCall<SendCustomMessageRequest, SendCustomMessageResponse>;
    /**
     * lncli: `subscribecustom`
     * SubscribeCustomMessages subscribes to a stream of incoming custom peer
     * messages.
     *
     * @generated from protobuf rpc: SubscribeCustomMessages(lnrpc.SubscribeCustomMessagesRequest) returns (stream lnrpc.CustomMessage);
     */
    subscribeCustomMessages(input: SubscribeCustomMessagesRequest, options?: RpcOptions): ServerStreamingCall<SubscribeCustomMessagesRequest, CustomMessage>;
    /**
     * lncli: `listaliases`
     * ListAliases returns the set of all aliases that have ever existed with
     * their confirmed SCID (if it exists) and/or the base SCID (in the case of
     * zero conf).
     *
     * @generated from protobuf rpc: ListAliases(lnrpc.ListAliasesRequest) returns (lnrpc.ListAliasesResponse);
     */
    listAliases(input: ListAliasesRequest, options?: RpcOptions): UnaryCall<ListAliasesRequest, ListAliasesResponse>;
    /**
     * @generated from protobuf rpc: LookupHtlc(lnrpc.LookupHtlcRequest) returns (lnrpc.LookupHtlcResponse);
     */
    lookupHtlc(input: LookupHtlcRequest, options?: RpcOptions): UnaryCall<LookupHtlcRequest, LookupHtlcResponse>;
}
// 
// Comments in this file will be directly parsed into the API
// Documentation as descriptions of the associated method, message, or field.
// These descriptions should go right above the definition of the object, and
// can be in either block or // comment format.
// 
// An RPC method can be matched to an lncli command by placing a line in the
// beginning of the description in exactly the following format:
// lncli: `methodname`
// 
// Failure to specify the exact name of the command will cause documentation
// generation to fail.
// 
// More information on how exactly the gRPC documentation is generated from
// this proto file can be found here:
// https://github.com/lightninglabs/lightning-api

/**
 * Lightning is the main RPC server of the daemon.
 *
 * @generated from protobuf service lnrpc.Lightning
 */
export class LightningClient implements ILightningClient, ServiceInfo {
    typeName = Lightning.typeName;
    methods = Lightning.methods;
    options = Lightning.options;
    constructor(private readonly _transport: RpcTransport) {
    }
    /**
     * lncli: `walletbalance`
     * WalletBalance returns total unspent outputs(confirmed and unconfirmed), all
     * confirmed unspent outputs and all unconfirmed unspent outputs under control
     * of the wallet.
     *
     * @generated from protobuf rpc: WalletBalance(lnrpc.WalletBalanceRequest) returns (lnrpc.WalletBalanceResponse);
     */
    walletBalance(input: WalletBalanceRequest, options?: RpcOptions): UnaryCall<WalletBalanceRequest, WalletBalanceResponse> {
        const method = this.methods[0], opt = this._transport.mergeOptions(options);
        return stackIntercept<WalletBalanceRequest, WalletBalanceResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `channelbalance`
     * ChannelBalance returns a report on the total funds across all open channels,
     * categorized in local/remote, pending local/remote and unsettled local/remote
     * balances.
     *
     * @generated from protobuf rpc: ChannelBalance(lnrpc.ChannelBalanceRequest) returns (lnrpc.ChannelBalanceResponse);
     */
    channelBalance(input: ChannelBalanceRequest, options?: RpcOptions): UnaryCall<ChannelBalanceRequest, ChannelBalanceResponse> {
        const method = this.methods[1], opt = this._transport.mergeOptions(options);
        return stackIntercept<ChannelBalanceRequest, ChannelBalanceResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `listchaintxns`
     * GetTransactions returns a list describing all the known transactions
     * relevant to the wallet.
     *
     * @generated from protobuf rpc: GetTransactions(lnrpc.GetTransactionsRequest) returns (lnrpc.TransactionDetails);
     */
    getTransactions(input: GetTransactionsRequest, options?: RpcOptions): UnaryCall<GetTransactionsRequest, TransactionDetails> {
        const method = this.methods[2], opt = this._transport.mergeOptions(options);
        return stackIntercept<GetTransactionsRequest, TransactionDetails>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `estimatefee`
     * EstimateFee asks the chain backend to estimate the fee rate and total fees
     * for a transaction that pays to multiple specified outputs.
     *
     * When using REST, the `AddrToAmount` map type can be set by appending
     * `&AddrToAmount[<address>]=<amount_to_send>` to the URL. Unfortunately this
     * map type doesn't appear in the REST API documentation because of a bug in
     * the grpc-gateway library.
     *
     * @generated from protobuf rpc: EstimateFee(lnrpc.EstimateFeeRequest) returns (lnrpc.EstimateFeeResponse);
     */
    estimateFee(input: EstimateFeeRequest, options?: RpcOptions): UnaryCall<EstimateFeeRequest, EstimateFeeResponse> {
        const method = this.methods[3], opt = this._transport.mergeOptions(options);
        return stackIntercept<EstimateFeeRequest, EstimateFeeResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `sendcoins`
     * SendCoins executes a request to send coins to a particular address. Unlike
     * SendMany, this RPC call only allows creating a single output at a time. If
     * neither target_conf, or sat_per_vbyte are set, then the internal wallet will
     * consult its fee model to determine a fee for the default confirmation
     * target.
     *
     * @generated from protobuf rpc: SendCoins(lnrpc.SendCoinsRequest) returns (lnrpc.SendCoinsResponse);
     */
    sendCoins(input: SendCoinsRequest, options?: RpcOptions): UnaryCall<SendCoinsRequest, SendCoinsResponse> {
        const method = this.methods[4], opt = this._transport.mergeOptions(options);
        return stackIntercept<SendCoinsRequest, SendCoinsResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `listunspent`
     * Deprecated, use walletrpc.ListUnspent instead.
     *
     * ListUnspent returns a list of all utxos spendable by the wallet with a
     * number of confirmations between the specified minimum and maximum.
     *
     * @generated from protobuf rpc: ListUnspent(lnrpc.ListUnspentRequest) returns (lnrpc.ListUnspentResponse);
     */
    listUnspent(input: ListUnspentRequest, options?: RpcOptions): UnaryCall<ListUnspentRequest, ListUnspentResponse> {
        const method = this.methods[5], opt = this._transport.mergeOptions(options);
        return stackIntercept<ListUnspentRequest, ListUnspentResponse>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * SubscribeTransactions creates a uni-directional stream from the server to
     * the client in which any newly discovered transactions relevant to the
     * wallet are sent over.
     *
     * @generated from protobuf rpc: SubscribeTransactions(lnrpc.GetTransactionsRequest) returns (stream lnrpc.Transaction);
     */
    subscribeTransactions(input: GetTransactionsRequest, options?: RpcOptions): ServerStreamingCall<GetTransactionsRequest, Transaction> {
        const method = this.methods[6], opt = this._transport.mergeOptions(options);
        return stackIntercept<GetTransactionsRequest, Transaction>("serverStreaming", this._transport, method, opt, input);
    }
    /**
     * lncli: `sendmany`
     * SendMany handles a request for a transaction that creates multiple specified
     * outputs in parallel. If neither target_conf, or sat_per_vbyte are set, then
     * the internal wallet will consult its fee model to determine a fee for the
     * default confirmation target.
     *
     * @generated from protobuf rpc: SendMany(lnrpc.SendManyRequest) returns (lnrpc.SendManyResponse);
     */
    sendMany(input: SendManyRequest, options?: RpcOptions): UnaryCall<SendManyRequest, SendManyResponse> {
        const method = this.methods[7], opt = this._transport.mergeOptions(options);
        return stackIntercept<SendManyRequest, SendManyResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `newaddress`
     * NewAddress creates a new address under control of the local wallet.
     *
     * @generated from protobuf rpc: NewAddress(lnrpc.NewAddressRequest) returns (lnrpc.NewAddressResponse);
     */
    newAddress(input: NewAddressRequest, options?: RpcOptions): UnaryCall<NewAddressRequest, NewAddressResponse> {
        const method = this.methods[8], opt = this._transport.mergeOptions(options);
        return stackIntercept<NewAddressRequest, NewAddressResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `signmessage`
     * SignMessage signs a message with this node's private key. The returned
     * signature string is `zbase32` encoded and pubkey recoverable, meaning that
     * only the message digest and signature are needed for verification.
     *
     * @generated from protobuf rpc: SignMessage(lnrpc.SignMessageRequest) returns (lnrpc.SignMessageResponse);
     */
    signMessage(input: SignMessageRequest, options?: RpcOptions): UnaryCall<SignMessageRequest, SignMessageResponse> {
        const method = this.methods[9], opt = this._transport.mergeOptions(options);
        return stackIntercept<SignMessageRequest, SignMessageResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `verifymessage`
     * VerifyMessage verifies a signature over a msg. The signature must be
     * zbase32 encoded and signed by an active node in the resident node's
     * channel database. In addition to returning the validity of the signature,
     * VerifyMessage also returns the recovered pubkey from the signature.
     *
     * @generated from protobuf rpc: VerifyMessage(lnrpc.VerifyMessageRequest) returns (lnrpc.VerifyMessageResponse);
     */
    verifyMessage(input: VerifyMessageRequest, options?: RpcOptions): UnaryCall<VerifyMessageRequest, VerifyMessageResponse> {
        const method = this.methods[10], opt = this._transport.mergeOptions(options);
        return stackIntercept<VerifyMessageRequest, VerifyMessageResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `connect`
     * ConnectPeer attempts to establish a connection to a remote peer. This is at
     * the networking level, and is used for communication between nodes. This is
     * distinct from establishing a channel with a peer.
     *
     * @generated from protobuf rpc: ConnectPeer(lnrpc.ConnectPeerRequest) returns (lnrpc.ConnectPeerResponse);
     */
    connectPeer(input: ConnectPeerRequest, options?: RpcOptions): UnaryCall<ConnectPeerRequest, ConnectPeerResponse> {
        const method = this.methods[11], opt = this._transport.mergeOptions(options);
        return stackIntercept<ConnectPeerRequest, ConnectPeerResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `disconnect`
     * DisconnectPeer attempts to disconnect one peer from another identified by a
     * given pubKey. In the case that we currently have a pending or active channel
     * with the target peer, then this action will be not be allowed.
     *
     * @generated from protobuf rpc: DisconnectPeer(lnrpc.DisconnectPeerRequest) returns (lnrpc.DisconnectPeerResponse);
     */
    disconnectPeer(input: DisconnectPeerRequest, options?: RpcOptions): UnaryCall<DisconnectPeerRequest, DisconnectPeerResponse> {
        const method = this.methods[12], opt = this._transport.mergeOptions(options);
        return stackIntercept<DisconnectPeerRequest, DisconnectPeerResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `listpeers`
     * ListPeers returns a verbose listing of all currently active peers.
     *
     * @generated from protobuf rpc: ListPeers(lnrpc.ListPeersRequest) returns (lnrpc.ListPeersResponse);
     */
    listPeers(input: ListPeersRequest, options?: RpcOptions): UnaryCall<ListPeersRequest, ListPeersResponse> {
        const method = this.methods[13], opt = this._transport.mergeOptions(options);
        return stackIntercept<ListPeersRequest, ListPeersResponse>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * SubscribePeerEvents creates a uni-directional stream from the server to
     * the client in which any events relevant to the state of peers are sent
     * over. Events include peers going online and offline.
     *
     * @generated from protobuf rpc: SubscribePeerEvents(lnrpc.PeerEventSubscription) returns (stream lnrpc.PeerEvent);
     */
    subscribePeerEvents(input: PeerEventSubscription, options?: RpcOptions): ServerStreamingCall<PeerEventSubscription, PeerEvent> {
        const method = this.methods[14], opt = this._transport.mergeOptions(options);
        return stackIntercept<PeerEventSubscription, PeerEvent>("serverStreaming", this._transport, method, opt, input);
    }
    /**
     * lncli: `getinfo`
     * GetInfo returns general information concerning the lightning node including
     * it's identity pubkey, alias, the chains it is connected to, and information
     * concerning the number of open+pending channels.
     *
     * @generated from protobuf rpc: GetInfo(lnrpc.GetInfoRequest) returns (lnrpc.GetInfoResponse);
     */
    getInfo(input: GetInfoRequest, options?: RpcOptions): UnaryCall<GetInfoRequest, GetInfoResponse> {
        const method = this.methods[15], opt = this._transport.mergeOptions(options);
        return stackIntercept<GetInfoRequest, GetInfoResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * * lncli: `getrecoveryinfo`
     * GetRecoveryInfo returns information concerning the recovery mode including
     * whether it's in a recovery mode, whether the recovery is finished, and the
     * progress made so far.
     *
     * @generated from protobuf rpc: GetRecoveryInfo(lnrpc.GetRecoveryInfoRequest) returns (lnrpc.GetRecoveryInfoResponse);
     */
    getRecoveryInfo(input: GetRecoveryInfoRequest, options?: RpcOptions): UnaryCall<GetRecoveryInfoRequest, GetRecoveryInfoResponse> {
        const method = this.methods[16], opt = this._transport.mergeOptions(options);
        return stackIntercept<GetRecoveryInfoRequest, GetRecoveryInfoResponse>("unary", this._transport, method, opt, input);
    }
    // TODO(roasbeef): merge with below with bool?

    /**
     * lncli: `pendingchannels`
     * PendingChannels returns a list of all the channels that are currently
     * considered "pending". A channel is pending if it has finished the funding
     * workflow and is waiting for confirmations for the funding txn, or is in the
     * process of closure, either initiated cooperatively or non-cooperatively.
     *
     * @generated from protobuf rpc: PendingChannels(lnrpc.PendingChannelsRequest) returns (lnrpc.PendingChannelsResponse);
     */
    pendingChannels(input: PendingChannelsRequest, options?: RpcOptions): UnaryCall<PendingChannelsRequest, PendingChannelsResponse> {
        const method = this.methods[17], opt = this._transport.mergeOptions(options);
        return stackIntercept<PendingChannelsRequest, PendingChannelsResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `listchannels`
     * ListChannels returns a description of all the open channels that this node
     * is a participant in.
     *
     * @generated from protobuf rpc: ListChannels(lnrpc.ListChannelsRequest) returns (lnrpc.ListChannelsResponse);
     */
    listChannels(input: ListChannelsRequest, options?: RpcOptions): UnaryCall<ListChannelsRequest, ListChannelsResponse> {
        const method = this.methods[18], opt = this._transport.mergeOptions(options);
        return stackIntercept<ListChannelsRequest, ListChannelsResponse>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * SubscribeChannelEvents creates a uni-directional stream from the server to
     * the client in which any updates relevant to the state of the channels are
     * sent over. Events include new active channels, inactive channels, and closed
     * channels.
     *
     * @generated from protobuf rpc: SubscribeChannelEvents(lnrpc.ChannelEventSubscription) returns (stream lnrpc.ChannelEventUpdate);
     */
    subscribeChannelEvents(input: ChannelEventSubscription, options?: RpcOptions): ServerStreamingCall<ChannelEventSubscription, ChannelEventUpdate> {
        const method = this.methods[19], opt = this._transport.mergeOptions(options);
        return stackIntercept<ChannelEventSubscription, ChannelEventUpdate>("serverStreaming", this._transport, method, opt, input);
    }
    /**
     * lncli: `closedchannels`
     * ClosedChannels returns a description of all the closed channels that
     * this node was a participant in.
     *
     * @generated from protobuf rpc: ClosedChannels(lnrpc.ClosedChannelsRequest) returns (lnrpc.ClosedChannelsResponse);
     */
    closedChannels(input: ClosedChannelsRequest, options?: RpcOptions): UnaryCall<ClosedChannelsRequest, ClosedChannelsResponse> {
        const method = this.methods[20], opt = this._transport.mergeOptions(options);
        return stackIntercept<ClosedChannelsRequest, ClosedChannelsResponse>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * OpenChannelSync is a synchronous version of the OpenChannel RPC call. This
     * call is meant to be consumed by clients to the REST proxy. As with all
     * other sync calls, all byte slices are intended to be populated as hex
     * encoded strings.
     *
     * @generated from protobuf rpc: OpenChannelSync(lnrpc.OpenChannelRequest) returns (lnrpc.ChannelPoint);
     */
    openChannelSync(input: OpenChannelRequest, options?: RpcOptions): UnaryCall<OpenChannelRequest, ChannelPoint> {
        const method = this.methods[21], opt = this._transport.mergeOptions(options);
        return stackIntercept<OpenChannelRequest, ChannelPoint>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `openchannel`
     * OpenChannel attempts to open a singly funded channel specified in the
     * request to a remote peer. Users are able to specify a target number of
     * blocks that the funding transaction should be confirmed in, or a manual fee
     * rate to us for the funding transaction. If neither are specified, then a
     * lax block confirmation target is used. Each OpenStatusUpdate will return
     * the pending channel ID of the in-progress channel. Depending on the
     * arguments specified in the OpenChannelRequest, this pending channel ID can
     * then be used to manually progress the channel funding flow.
     *
     * @generated from protobuf rpc: OpenChannel(lnrpc.OpenChannelRequest) returns (stream lnrpc.OpenStatusUpdate);
     */
    openChannel(input: OpenChannelRequest, options?: RpcOptions): ServerStreamingCall<OpenChannelRequest, OpenStatusUpdate> {
        const method = this.methods[22], opt = this._transport.mergeOptions(options);
        return stackIntercept<OpenChannelRequest, OpenStatusUpdate>("serverStreaming", this._transport, method, opt, input);
    }
    /**
     * lncli: `batchopenchannel`
     * BatchOpenChannel attempts to open multiple single-funded channels in a
     * single transaction in an atomic way. This means either all channel open
     * requests succeed at once or all attempts are aborted if any of them fail.
     * This is the safer variant of using PSBTs to manually fund a batch of
     * channels through the OpenChannel RPC.
     *
     * @generated from protobuf rpc: BatchOpenChannel(lnrpc.BatchOpenChannelRequest) returns (lnrpc.BatchOpenChannelResponse);
     */
    batchOpenChannel(input: BatchOpenChannelRequest, options?: RpcOptions): UnaryCall<BatchOpenChannelRequest, BatchOpenChannelResponse> {
        const method = this.methods[23], opt = this._transport.mergeOptions(options);
        return stackIntercept<BatchOpenChannelRequest, BatchOpenChannelResponse>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * FundingStateStep is an advanced funding related call that allows the caller
     * to either execute some preparatory steps for a funding workflow, or
     * manually progress a funding workflow. The primary way a funding flow is
     * identified is via its pending channel ID. As an example, this method can be
     * used to specify that we're expecting a funding flow for a particular
     * pending channel ID, for which we need to use specific parameters.
     * Alternatively, this can be used to interactively drive PSBT signing for
     * funding for partially complete funding transactions.
     *
     * @generated from protobuf rpc: FundingStateStep(lnrpc.FundingTransitionMsg) returns (lnrpc.FundingStateStepResp);
     */
    fundingStateStep(input: FundingTransitionMsg, options?: RpcOptions): UnaryCall<FundingTransitionMsg, FundingStateStepResp> {
        const method = this.methods[24], opt = this._transport.mergeOptions(options);
        return stackIntercept<FundingTransitionMsg, FundingStateStepResp>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * ChannelAcceptor dispatches a bi-directional streaming RPC in which
     * OpenChannel requests are sent to the client and the client responds with
     * a boolean that tells LND whether or not to accept the channel. This allows
     * node operators to specify their own criteria for accepting inbound channels
     * through a single persistent connection.
     *
     * @generated from protobuf rpc: ChannelAcceptor(stream lnrpc.ChannelAcceptResponse) returns (stream lnrpc.ChannelAcceptRequest);
     */
    channelAcceptor(options?: RpcOptions): DuplexStreamingCall<ChannelAcceptResponse, ChannelAcceptRequest> {
        const method = this.methods[25], opt = this._transport.mergeOptions(options);
        return stackIntercept<ChannelAcceptResponse, ChannelAcceptRequest>("duplex", this._transport, method, opt);
    }
    /**
     * lncli: `closechannel`
     * CloseChannel attempts to close an active channel identified by its channel
     * outpoint (ChannelPoint). The actions of this method can additionally be
     * augmented to attempt a force close after a timeout period in the case of an
     * inactive peer. If a non-force close (cooperative closure) is requested,
     * then the user can specify either a target number of blocks until the
     * closure transaction is confirmed, or a manual fee rate. If neither are
     * specified, then a default lax, block confirmation target is used.
     *
     * @generated from protobuf rpc: CloseChannel(lnrpc.CloseChannelRequest) returns (stream lnrpc.CloseStatusUpdate);
     */
    closeChannel(input: CloseChannelRequest, options?: RpcOptions): ServerStreamingCall<CloseChannelRequest, CloseStatusUpdate> {
        const method = this.methods[26], opt = this._transport.mergeOptions(options);
        return stackIntercept<CloseChannelRequest, CloseStatusUpdate>("serverStreaming", this._transport, method, opt, input);
    }
    /**
     * lncli: `abandonchannel`
     * AbandonChannel removes all channel state from the database except for a
     * close summary. This method can be used to get rid of permanently unusable
     * channels due to bugs fixed in newer versions of lnd. This method can also be
     * used to remove externally funded channels where the funding transaction was
     * never broadcast. Only available for non-externally funded channels in dev
     * build.
     *
     * @generated from protobuf rpc: AbandonChannel(lnrpc.AbandonChannelRequest) returns (lnrpc.AbandonChannelResponse);
     */
    abandonChannel(input: AbandonChannelRequest, options?: RpcOptions): UnaryCall<AbandonChannelRequest, AbandonChannelResponse> {
        const method = this.methods[27], opt = this._transport.mergeOptions(options);
        return stackIntercept<AbandonChannelRequest, AbandonChannelResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `sendpayment`
     * Deprecated, use routerrpc.SendPaymentV2. SendPayment dispatches a
     * bi-directional streaming RPC for sending payments through the Lightning
     * Network. A single RPC invocation creates a persistent bi-directional
     * stream allowing clients to rapidly send payments through the Lightning
     * Network with a single persistent connection.
     *
     * @deprecated
     * @generated from protobuf rpc: SendPayment(stream lnrpc.SendRequest) returns (stream lnrpc.SendResponse);
     */
    sendPayment(options?: RpcOptions): DuplexStreamingCall<SendRequest, SendResponse> {
        const method = this.methods[28], opt = this._transport.mergeOptions(options);
        return stackIntercept<SendRequest, SendResponse>("duplex", this._transport, method, opt);
    }
    /**
     *
     * SendPaymentSync is the synchronous non-streaming version of SendPayment.
     * This RPC is intended to be consumed by clients of the REST proxy.
     * Additionally, this RPC expects the destination's public key and the payment
     * hash (if any) to be encoded as hex strings.
     *
     * @generated from protobuf rpc: SendPaymentSync(lnrpc.SendRequest) returns (lnrpc.SendResponse);
     */
    sendPaymentSync(input: SendRequest, options?: RpcOptions): UnaryCall<SendRequest, SendResponse> {
        const method = this.methods[29], opt = this._transport.mergeOptions(options);
        return stackIntercept<SendRequest, SendResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `sendtoroute`
     * Deprecated, use routerrpc.SendToRouteV2. SendToRoute is a bi-directional
     * streaming RPC for sending payment through the Lightning Network. This
     * method differs from SendPayment in that it allows users to specify a full
     * route manually. This can be used for things like rebalancing, and atomic
     * swaps.
     *
     * @deprecated
     * @generated from protobuf rpc: SendToRoute(stream lnrpc.SendToRouteRequest) returns (stream lnrpc.SendResponse);
     */
    sendToRoute(options?: RpcOptions): DuplexStreamingCall<SendToRouteRequest, SendResponse> {
        const method = this.methods[30], opt = this._transport.mergeOptions(options);
        return stackIntercept<SendToRouteRequest, SendResponse>("duplex", this._transport, method, opt);
    }
    /**
     *
     * SendToRouteSync is a synchronous version of SendToRoute. It Will block
     * until the payment either fails or succeeds.
     *
     * @generated from protobuf rpc: SendToRouteSync(lnrpc.SendToRouteRequest) returns (lnrpc.SendResponse);
     */
    sendToRouteSync(input: SendToRouteRequest, options?: RpcOptions): UnaryCall<SendToRouteRequest, SendResponse> {
        const method = this.methods[31], opt = this._transport.mergeOptions(options);
        return stackIntercept<SendToRouteRequest, SendResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `addinvoice`
     * AddInvoice attempts to add a new invoice to the invoice database. Any
     * duplicated invoices are rejected, therefore all invoices *must* have a
     * unique payment preimage.
     *
     * @generated from protobuf rpc: AddInvoice(lnrpc.Invoice) returns (lnrpc.AddInvoiceResponse);
     */
    addInvoice(input: Invoice, options?: RpcOptions): UnaryCall<Invoice, AddInvoiceResponse> {
        const method = this.methods[32], opt = this._transport.mergeOptions(options);
        return stackIntercept<Invoice, AddInvoiceResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `listinvoices`
     * ListInvoices returns a list of all the invoices currently stored within the
     * database. Any active debug invoices are ignored. It has full support for
     * paginated responses, allowing users to query for specific invoices through
     * their add_index. This can be done by using either the first_index_offset or
     * last_index_offset fields included in the response as the index_offset of the
     * next request. By default, the first 100 invoices created will be returned.
     * Backwards pagination is also supported through the Reversed flag.
     *
     * @generated from protobuf rpc: ListInvoices(lnrpc.ListInvoiceRequest) returns (lnrpc.ListInvoiceResponse);
     */
    listInvoices(input: ListInvoiceRequest, options?: RpcOptions): UnaryCall<ListInvoiceRequest, ListInvoiceResponse> {
        const method = this.methods[33], opt = this._transport.mergeOptions(options);
        return stackIntercept<ListInvoiceRequest, ListInvoiceResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `lookupinvoice`
     * LookupInvoice attempts to look up an invoice according to its payment hash.
     * The passed payment hash *must* be exactly 32 bytes, if not, an error is
     * returned.
     *
     * @generated from protobuf rpc: LookupInvoice(lnrpc.PaymentHash) returns (lnrpc.Invoice);
     */
    lookupInvoice(input: PaymentHash, options?: RpcOptions): UnaryCall<PaymentHash, Invoice> {
        const method = this.methods[34], opt = this._transport.mergeOptions(options);
        return stackIntercept<PaymentHash, Invoice>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * SubscribeInvoices returns a uni-directional stream (server -> client) for
     * notifying the client of newly added/settled invoices. The caller can
     * optionally specify the add_index and/or the settle_index. If the add_index
     * is specified, then we'll first start by sending add invoice events for all
     * invoices with an add_index greater than the specified value. If the
     * settle_index is specified, the next, we'll send out all settle events for
     * invoices with a settle_index greater than the specified value. One or both
     * of these fields can be set. If no fields are set, then we'll only send out
     * the latest add/settle events.
     *
     * @generated from protobuf rpc: SubscribeInvoices(lnrpc.InvoiceSubscription) returns (stream lnrpc.Invoice);
     */
    subscribeInvoices(input: InvoiceSubscription, options?: RpcOptions): ServerStreamingCall<InvoiceSubscription, Invoice> {
        const method = this.methods[35], opt = this._transport.mergeOptions(options);
        return stackIntercept<InvoiceSubscription, Invoice>("serverStreaming", this._transport, method, opt, input);
    }
    /**
     * lncli: `decodepayreq`
     * DecodePayReq takes an encoded payment request string and attempts to decode
     * it, returning a full description of the conditions encoded within the
     * payment request.
     *
     * @generated from protobuf rpc: DecodePayReq(lnrpc.PayReqString) returns (lnrpc.PayReq);
     */
    decodePayReq(input: PayReqString, options?: RpcOptions): UnaryCall<PayReqString, PayReq> {
        const method = this.methods[36], opt = this._transport.mergeOptions(options);
        return stackIntercept<PayReqString, PayReq>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `listpayments`
     * ListPayments returns a list of all outgoing payments.
     *
     * @generated from protobuf rpc: ListPayments(lnrpc.ListPaymentsRequest) returns (lnrpc.ListPaymentsResponse);
     */
    listPayments(input: ListPaymentsRequest, options?: RpcOptions): UnaryCall<ListPaymentsRequest, ListPaymentsResponse> {
        const method = this.methods[37], opt = this._transport.mergeOptions(options);
        return stackIntercept<ListPaymentsRequest, ListPaymentsResponse>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * DeletePayment deletes an outgoing payment from DB. Note that it will not
     * attempt to delete an In-Flight payment, since that would be unsafe.
     *
     * @generated from protobuf rpc: DeletePayment(lnrpc.DeletePaymentRequest) returns (lnrpc.DeletePaymentResponse);
     */
    deletePayment(input: DeletePaymentRequest, options?: RpcOptions): UnaryCall<DeletePaymentRequest, DeletePaymentResponse> {
        const method = this.methods[38], opt = this._transport.mergeOptions(options);
        return stackIntercept<DeletePaymentRequest, DeletePaymentResponse>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * DeleteAllPayments deletes all outgoing payments from DB. Note that it will
     * not attempt to delete In-Flight payments, since that would be unsafe.
     *
     * @generated from protobuf rpc: DeleteAllPayments(lnrpc.DeleteAllPaymentsRequest) returns (lnrpc.DeleteAllPaymentsResponse);
     */
    deleteAllPayments(input: DeleteAllPaymentsRequest, options?: RpcOptions): UnaryCall<DeleteAllPaymentsRequest, DeleteAllPaymentsResponse> {
        const method = this.methods[39], opt = this._transport.mergeOptions(options);
        return stackIntercept<DeleteAllPaymentsRequest, DeleteAllPaymentsResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `describegraph`
     * DescribeGraph returns a description of the latest graph state from the
     * point of view of the node. The graph information is partitioned into two
     * components: all the nodes/vertexes, and all the edges that connect the
     * vertexes themselves. As this is a directed graph, the edges also contain
     * the node directional specific routing policy which includes: the time lock
     * delta, fee information, etc.
     *
     * @generated from protobuf rpc: DescribeGraph(lnrpc.ChannelGraphRequest) returns (lnrpc.ChannelGraph);
     */
    describeGraph(input: ChannelGraphRequest, options?: RpcOptions): UnaryCall<ChannelGraphRequest, ChannelGraph> {
        const method = this.methods[40], opt = this._transport.mergeOptions(options);
        return stackIntercept<ChannelGraphRequest, ChannelGraph>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `getnodemetrics`
     * GetNodeMetrics returns node metrics calculated from the graph. Currently
     * the only supported metric is betweenness centrality of individual nodes.
     *
     * @generated from protobuf rpc: GetNodeMetrics(lnrpc.NodeMetricsRequest) returns (lnrpc.NodeMetricsResponse);
     */
    getNodeMetrics(input: NodeMetricsRequest, options?: RpcOptions): UnaryCall<NodeMetricsRequest, NodeMetricsResponse> {
        const method = this.methods[41], opt = this._transport.mergeOptions(options);
        return stackIntercept<NodeMetricsRequest, NodeMetricsResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `getchaninfo`
     * GetChanInfo returns the latest authenticated network announcement for the
     * given channel identified by its channel ID: an 8-byte integer which
     * uniquely identifies the location of transaction's funding output within the
     * blockchain.
     *
     * @generated from protobuf rpc: GetChanInfo(lnrpc.ChanInfoRequest) returns (lnrpc.ChannelEdge);
     */
    getChanInfo(input: ChanInfoRequest, options?: RpcOptions): UnaryCall<ChanInfoRequest, ChannelEdge> {
        const method = this.methods[42], opt = this._transport.mergeOptions(options);
        return stackIntercept<ChanInfoRequest, ChannelEdge>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `getnodeinfo`
     * GetNodeInfo returns the latest advertised, aggregated, and authenticated
     * channel information for the specified node identified by its public key.
     *
     * @generated from protobuf rpc: GetNodeInfo(lnrpc.NodeInfoRequest) returns (lnrpc.NodeInfo);
     */
    getNodeInfo(input: NodeInfoRequest, options?: RpcOptions): UnaryCall<NodeInfoRequest, NodeInfo> {
        const method = this.methods[43], opt = this._transport.mergeOptions(options);
        return stackIntercept<NodeInfoRequest, NodeInfo>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `queryroutes`
     * QueryRoutes attempts to query the daemon's Channel Router for a possible
     * route to a target destination capable of carrying a specific amount of
     * satoshis. The returned route contains the full details required to craft and
     * send an HTLC, also including the necessary information that should be
     * present within the Sphinx packet encapsulated within the HTLC.
     *
     * When using REST, the `dest_custom_records` map type can be set by appending
     * `&dest_custom_records[<record_number>]=<record_data_base64_url_encoded>`
     * to the URL. Unfortunately this map type doesn't appear in the REST API
     * documentation because of a bug in the grpc-gateway library.
     *
     * @generated from protobuf rpc: QueryRoutes(lnrpc.QueryRoutesRequest) returns (lnrpc.QueryRoutesResponse);
     */
    queryRoutes(input: QueryRoutesRequest, options?: RpcOptions): UnaryCall<QueryRoutesRequest, QueryRoutesResponse> {
        const method = this.methods[44], opt = this._transport.mergeOptions(options);
        return stackIntercept<QueryRoutesRequest, QueryRoutesResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `getnetworkinfo`
     * GetNetworkInfo returns some basic stats about the known channel graph from
     * the point of view of the node.
     *
     * @generated from protobuf rpc: GetNetworkInfo(lnrpc.NetworkInfoRequest) returns (lnrpc.NetworkInfo);
     */
    getNetworkInfo(input: NetworkInfoRequest, options?: RpcOptions): UnaryCall<NetworkInfoRequest, NetworkInfo> {
        const method = this.methods[45], opt = this._transport.mergeOptions(options);
        return stackIntercept<NetworkInfoRequest, NetworkInfo>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `stop`
     * StopDaemon will send a shutdown request to the interrupt handler, triggering
     * a graceful shutdown of the daemon.
     *
     * @generated from protobuf rpc: StopDaemon(lnrpc.StopRequest) returns (lnrpc.StopResponse);
     */
    stopDaemon(input: StopRequest, options?: RpcOptions): UnaryCall<StopRequest, StopResponse> {
        const method = this.methods[46], opt = this._transport.mergeOptions(options);
        return stackIntercept<StopRequest, StopResponse>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * SubscribeChannelGraph launches a streaming RPC that allows the caller to
     * receive notifications upon any changes to the channel graph topology from
     * the point of view of the responding node. Events notified include: new
     * nodes coming online, nodes updating their authenticated attributes, new
     * channels being advertised, updates in the routing policy for a directional
     * channel edge, and when channels are closed on-chain.
     *
     * @generated from protobuf rpc: SubscribeChannelGraph(lnrpc.GraphTopologySubscription) returns (stream lnrpc.GraphTopologyUpdate);
     */
    subscribeChannelGraph(input: GraphTopologySubscription, options?: RpcOptions): ServerStreamingCall<GraphTopologySubscription, GraphTopologyUpdate> {
        const method = this.methods[47], opt = this._transport.mergeOptions(options);
        return stackIntercept<GraphTopologySubscription, GraphTopologyUpdate>("serverStreaming", this._transport, method, opt, input);
    }
    /**
     * lncli: `debuglevel`
     * DebugLevel allows a caller to programmatically set the logging verbosity of
     * lnd. The logging can be targeted according to a coarse daemon-wide logging
     * level, or in a granular fashion to specify the logging for a target
     * sub-system.
     *
     * @generated from protobuf rpc: DebugLevel(lnrpc.DebugLevelRequest) returns (lnrpc.DebugLevelResponse);
     */
    debugLevel(input: DebugLevelRequest, options?: RpcOptions): UnaryCall<DebugLevelRequest, DebugLevelResponse> {
        const method = this.methods[48], opt = this._transport.mergeOptions(options);
        return stackIntercept<DebugLevelRequest, DebugLevelResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `feereport`
     * FeeReport allows the caller to obtain a report detailing the current fee
     * schedule enforced by the node globally for each channel.
     *
     * @generated from protobuf rpc: FeeReport(lnrpc.FeeReportRequest) returns (lnrpc.FeeReportResponse);
     */
    feeReport(input: FeeReportRequest, options?: RpcOptions): UnaryCall<FeeReportRequest, FeeReportResponse> {
        const method = this.methods[49], opt = this._transport.mergeOptions(options);
        return stackIntercept<FeeReportRequest, FeeReportResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `updatechanpolicy`
     * UpdateChannelPolicy allows the caller to update the fee schedule and
     * channel policies for all channels globally, or a particular channel.
     *
     * @generated from protobuf rpc: UpdateChannelPolicy(lnrpc.PolicyUpdateRequest) returns (lnrpc.PolicyUpdateResponse);
     */
    updateChannelPolicy(input: PolicyUpdateRequest, options?: RpcOptions): UnaryCall<PolicyUpdateRequest, PolicyUpdateResponse> {
        const method = this.methods[50], opt = this._transport.mergeOptions(options);
        return stackIntercept<PolicyUpdateRequest, PolicyUpdateResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `fwdinghistory`
     * ForwardingHistory allows the caller to query the htlcswitch for a record of
     * all HTLCs forwarded within the target time range, and integer offset
     * within that time range, for a maximum number of events. If no maximum number
     * of events is specified, up to 100 events will be returned. If no time-range
     * is specified, then events will be returned in the order that they occured.
     *
     * A list of forwarding events are returned. The size of each forwarding event
     * is 40 bytes, and the max message size able to be returned in gRPC is 4 MiB.
     * As a result each message can only contain 50k entries. Each response has
     * the index offset of the last entry. The index offset can be provided to the
     * request to allow the caller to skip a series of records.
     *
     * @generated from protobuf rpc: ForwardingHistory(lnrpc.ForwardingHistoryRequest) returns (lnrpc.ForwardingHistoryResponse);
     */
    forwardingHistory(input: ForwardingHistoryRequest, options?: RpcOptions): UnaryCall<ForwardingHistoryRequest, ForwardingHistoryResponse> {
        const method = this.methods[51], opt = this._transport.mergeOptions(options);
        return stackIntercept<ForwardingHistoryRequest, ForwardingHistoryResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `exportchanbackup`
     * ExportChannelBackup attempts to return an encrypted static channel backup
     * for the target channel identified by it channel point. The backup is
     * encrypted with a key generated from the aezeed seed of the user. The
     * returned backup can either be restored using the RestoreChannelBackup
     * method once lnd is running, or via the InitWallet and UnlockWallet methods
     * from the WalletUnlocker service.
     *
     * @generated from protobuf rpc: ExportChannelBackup(lnrpc.ExportChannelBackupRequest) returns (lnrpc.ChannelBackup);
     */
    exportChannelBackup(input: ExportChannelBackupRequest, options?: RpcOptions): UnaryCall<ExportChannelBackupRequest, ChannelBackup> {
        const method = this.methods[52], opt = this._transport.mergeOptions(options);
        return stackIntercept<ExportChannelBackupRequest, ChannelBackup>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * ExportAllChannelBackups returns static channel backups for all existing
     * channels known to lnd. A set of regular singular static channel backups for
     * each channel are returned. Additionally, a multi-channel backup is returned
     * as well, which contains a single encrypted blob containing the backups of
     * each channel.
     *
     * @generated from protobuf rpc: ExportAllChannelBackups(lnrpc.ChanBackupExportRequest) returns (lnrpc.ChanBackupSnapshot);
     */
    exportAllChannelBackups(input: ChanBackupExportRequest, options?: RpcOptions): UnaryCall<ChanBackupExportRequest, ChanBackupSnapshot> {
        const method = this.methods[53], opt = this._transport.mergeOptions(options);
        return stackIntercept<ChanBackupExportRequest, ChanBackupSnapshot>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * VerifyChanBackup allows a caller to verify the integrity of a channel backup
     * snapshot. This method will accept either a packed Single or a packed Multi.
     * Specifying both will result in an error.
     *
     * @generated from protobuf rpc: VerifyChanBackup(lnrpc.ChanBackupSnapshot) returns (lnrpc.VerifyChanBackupResponse);
     */
    verifyChanBackup(input: ChanBackupSnapshot, options?: RpcOptions): UnaryCall<ChanBackupSnapshot, VerifyChanBackupResponse> {
        const method = this.methods[54], opt = this._transport.mergeOptions(options);
        return stackIntercept<ChanBackupSnapshot, VerifyChanBackupResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `restorechanbackup`
     * RestoreChannelBackups accepts a set of singular channel backups, or a
     * single encrypted multi-chan backup and attempts to recover any funds
     * remaining within the channel. If we are able to unpack the backup, then the
     * new channel will be shown under listchannels, as well as pending channels.
     *
     * @generated from protobuf rpc: RestoreChannelBackups(lnrpc.RestoreChanBackupRequest) returns (lnrpc.RestoreBackupResponse);
     */
    restoreChannelBackups(input: RestoreChanBackupRequest, options?: RpcOptions): UnaryCall<RestoreChanBackupRequest, RestoreBackupResponse> {
        const method = this.methods[55], opt = this._transport.mergeOptions(options);
        return stackIntercept<RestoreChanBackupRequest, RestoreBackupResponse>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * SubscribeChannelBackups allows a client to sub-subscribe to the most up to
     * date information concerning the state of all channel backups. Each time a
     * new channel is added, we return the new set of channels, along with a
     * multi-chan backup containing the backup info for all channels. Each time a
     * channel is closed, we send a new update, which contains new new chan back
     * ups, but the updated set of encrypted multi-chan backups with the closed
     * channel(s) removed.
     *
     * @generated from protobuf rpc: SubscribeChannelBackups(lnrpc.ChannelBackupSubscription) returns (stream lnrpc.ChanBackupSnapshot);
     */
    subscribeChannelBackups(input: ChannelBackupSubscription, options?: RpcOptions): ServerStreamingCall<ChannelBackupSubscription, ChanBackupSnapshot> {
        const method = this.methods[56], opt = this._transport.mergeOptions(options);
        return stackIntercept<ChannelBackupSubscription, ChanBackupSnapshot>("serverStreaming", this._transport, method, opt, input);
    }
    /**
     * lncli: `bakemacaroon`
     * BakeMacaroon allows the creation of a new macaroon with custom read and
     * write permissions. No first-party caveats are added since this can be done
     * offline.
     *
     * @generated from protobuf rpc: BakeMacaroon(lnrpc.BakeMacaroonRequest) returns (lnrpc.BakeMacaroonResponse);
     */
    bakeMacaroon(input: BakeMacaroonRequest, options?: RpcOptions): UnaryCall<BakeMacaroonRequest, BakeMacaroonResponse> {
        const method = this.methods[57], opt = this._transport.mergeOptions(options);
        return stackIntercept<BakeMacaroonRequest, BakeMacaroonResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `listmacaroonids`
     * ListMacaroonIDs returns all root key IDs that are in use.
     *
     * @generated from protobuf rpc: ListMacaroonIDs(lnrpc.ListMacaroonIDsRequest) returns (lnrpc.ListMacaroonIDsResponse);
     */
    listMacaroonIDs(input: ListMacaroonIDsRequest, options?: RpcOptions): UnaryCall<ListMacaroonIDsRequest, ListMacaroonIDsResponse> {
        const method = this.methods[58], opt = this._transport.mergeOptions(options);
        return stackIntercept<ListMacaroonIDsRequest, ListMacaroonIDsResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `deletemacaroonid`
     * DeleteMacaroonID deletes the specified macaroon ID and invalidates all
     * macaroons derived from that ID.
     *
     * @generated from protobuf rpc: DeleteMacaroonID(lnrpc.DeleteMacaroonIDRequest) returns (lnrpc.DeleteMacaroonIDResponse);
     */
    deleteMacaroonID(input: DeleteMacaroonIDRequest, options?: RpcOptions): UnaryCall<DeleteMacaroonIDRequest, DeleteMacaroonIDResponse> {
        const method = this.methods[59], opt = this._transport.mergeOptions(options);
        return stackIntercept<DeleteMacaroonIDRequest, DeleteMacaroonIDResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `listpermissions`
     * ListPermissions lists all RPC method URIs and their required macaroon
     * permissions to access them.
     *
     * @generated from protobuf rpc: ListPermissions(lnrpc.ListPermissionsRequest) returns (lnrpc.ListPermissionsResponse);
     */
    listPermissions(input: ListPermissionsRequest, options?: RpcOptions): UnaryCall<ListPermissionsRequest, ListPermissionsResponse> {
        const method = this.methods[60], opt = this._transport.mergeOptions(options);
        return stackIntercept<ListPermissionsRequest, ListPermissionsResponse>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * CheckMacaroonPermissions checks whether a request follows the constraints
     * imposed on the macaroon and that the macaroon is authorized to follow the
     * provided permissions.
     *
     * @generated from protobuf rpc: CheckMacaroonPermissions(lnrpc.CheckMacPermRequest) returns (lnrpc.CheckMacPermResponse);
     */
    checkMacaroonPermissions(input: CheckMacPermRequest, options?: RpcOptions): UnaryCall<CheckMacPermRequest, CheckMacPermResponse> {
        const method = this.methods[61], opt = this._transport.mergeOptions(options);
        return stackIntercept<CheckMacPermRequest, CheckMacPermResponse>("unary", this._transport, method, opt, input);
    }
    /**
     *
     * RegisterRPCMiddleware adds a new gRPC middleware to the interceptor chain. A
     * gRPC middleware is software component external to lnd that aims to add
     * additional business logic to lnd by observing/intercepting/validating
     * incoming gRPC client requests and (if needed) replacing/overwriting outgoing
     * messages before they're sent to the client. When registering the middleware
     * must identify itself and indicate what custom macaroon caveats it wants to
     * be responsible for. Only requests that contain a macaroon with that specific
     * custom caveat are then sent to the middleware for inspection. The other
     * option is to register for the read-only mode in which all requests/responses
     * are forwarded for interception to the middleware but the middleware is not
     * allowed to modify any responses. As a security measure, _no_ middleware can
     * modify responses for requests made with _unencumbered_ macaroons!
     *
     * @generated from protobuf rpc: RegisterRPCMiddleware(stream lnrpc.RPCMiddlewareResponse) returns (stream lnrpc.RPCMiddlewareRequest);
     */
    registerRPCMiddleware(options?: RpcOptions): DuplexStreamingCall<RPCMiddlewareResponse, RPCMiddlewareRequest> {
        const method = this.methods[62], opt = this._transport.mergeOptions(options);
        return stackIntercept<RPCMiddlewareResponse, RPCMiddlewareRequest>("duplex", this._transport, method, opt);
    }
    /**
     * lncli: `sendcustom`
     * SendCustomMessage sends a custom peer message.
     *
     * @generated from protobuf rpc: SendCustomMessage(lnrpc.SendCustomMessageRequest) returns (lnrpc.SendCustomMessageResponse);
     */
    sendCustomMessage(input: SendCustomMessageRequest, options?: RpcOptions): UnaryCall<SendCustomMessageRequest, SendCustomMessageResponse> {
        const method = this.methods[63], opt = this._transport.mergeOptions(options);
        return stackIntercept<SendCustomMessageRequest, SendCustomMessageResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * lncli: `subscribecustom`
     * SubscribeCustomMessages subscribes to a stream of incoming custom peer
     * messages.
     *
     * @generated from protobuf rpc: SubscribeCustomMessages(lnrpc.SubscribeCustomMessagesRequest) returns (stream lnrpc.CustomMessage);
     */
    subscribeCustomMessages(input: SubscribeCustomMessagesRequest, options?: RpcOptions): ServerStreamingCall<SubscribeCustomMessagesRequest, CustomMessage> {
        const method = this.methods[64], opt = this._transport.mergeOptions(options);
        return stackIntercept<SubscribeCustomMessagesRequest, CustomMessage>("serverStreaming", this._transport, method, opt, input);
    }
    /**
     * lncli: `listaliases`
     * ListAliases returns the set of all aliases that have ever existed with
     * their confirmed SCID (if it exists) and/or the base SCID (in the case of
     * zero conf).
     *
     * @generated from protobuf rpc: ListAliases(lnrpc.ListAliasesRequest) returns (lnrpc.ListAliasesResponse);
     */
    listAliases(input: ListAliasesRequest, options?: RpcOptions): UnaryCall<ListAliasesRequest, ListAliasesResponse> {
        const method = this.methods[65], opt = this._transport.mergeOptions(options);
        return stackIntercept<ListAliasesRequest, ListAliasesResponse>("unary", this._transport, method, opt, input);
    }
    /**
     * @generated from protobuf rpc: LookupHtlc(lnrpc.LookupHtlcRequest) returns (lnrpc.LookupHtlcResponse);
     */
    lookupHtlc(input: LookupHtlcRequest, options?: RpcOptions): UnaryCall<LookupHtlcRequest, LookupHtlcResponse> {
        const method = this.methods[66], opt = this._transport.mergeOptions(options);
        return stackIntercept<LookupHtlcRequest, LookupHtlcResponse>("unary", this._transport, method, opt, input);
    }
}
